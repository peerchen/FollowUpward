{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "catalyst ingest-exchange -x binance -i ltc_usdt -f minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "catalyst ingest-exchange -x binance -i xrp_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i btc_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i eth_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i bnb_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i eos_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i neo_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i trx_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i ltc_usdt -f minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start terminal from anaconda/environments/catalyst\n",
    "# in terminal the catalyst environment should be active, which can be checked by conda info --all\n",
    "# jupyter lab work doesn't work as it doesn't switch to the catalyst environment\n",
    "# start jupyter notebook by: jupyter notebook\n",
    "%load_ext catalyst\n",
    "# required to activate catalyst magic words \n",
    "\n",
    "\n",
    "# Setup matplotlib to display graphs inline in this Notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "pixiedust.optOut()\n",
    "\n",
    "# magic line to be inserted as first line of cell\n",
    "# %%pixie_debugger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Catalyst historic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pixiedust\n",
    "\n",
    "from catalyst.api import symbol, symbols\n",
    "from catalyst.protocol import BarData\n",
    "cur_cand = ['xrp_usdt', 'btc_usdt'] \n",
    "data_keys = ['open', 'high', 'low', 'close', 'volume'] # , 'price'\n",
    "\n",
    "\n",
    "def catalyst2picklepandas(context, data: BarData):\n",
    "    \"reads catalyst data for trading pairs and stores them in a testfile for subsequent usage\"\n",
    "    test = currencies = dict()\n",
    "    filename = os.getcwd() + '/df-test.pydata'\n",
    "\n",
    "    for pair in cur_cand:\n",
    "        current = data.history(symbol(pair), data_keys, 239*24*60, '1T')\n",
    "        currencies[pair] = current\n",
    "        print(current.head())\n",
    "        print(current.tail())\n",
    "\n",
    "    print(\"got catalyst history data\")\n",
    "    df_f = open(filename, 'wb')\n",
    "    pickle.dump(currencies, df_f)\n",
    "    df_f.close()\n",
    "    print(\"data frame is written\")\n",
    "#    df_f = open(filename, 'rb')\n",
    "#    test = pickle.load(df_f)\n",
    "#    df_f.close()\n",
    "#    print(test)\n",
    "    return None\n",
    "\n",
    "def feature_normalize(filename: str):\n",
    "    currencies = dict()\n",
    "    df_f = open(filename, 'rb')\n",
    "    currencies = pickle.load(df_f)\n",
    "    df_f.close()\n",
    "#    combined_curr = combine_catalyst_data(currencies)\n",
    "    aggregate_currencies = pair_aggregation(currencies)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "agg_minutes = [1, 2] # minutes = T\n",
    "time_aggregations = {'1T': 4, '2T': 4} # , '4T':4\n",
    "minute_data = pd.DataFrame() # required to use minute data in apply\n",
    "#time_aggregations = dict(zip(zip([str(n) for n in agg_minutes] + ['T' for x in agg_minutes]), [4 for x in agg_minutes])) # , '4T':4\n",
    "print(time_aggregations)\n",
    "vol_base_period = '1D'\n",
    "sell_threshold = -2 # in per mille\n",
    "buy_threshold = 10 # in per mille\n",
    "transaction_fee = 1 # in per mille, i.e. 0,1%\n",
    "best_n = 10\n",
    "\n",
    "def check_tag(tg, ltg):\n",
    "    return abs(tg) == abs(ltg)\n",
    "    \n",
    "def add_period_specific_labels(df: pd.DataFrame):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "#            df.apply(lambda x: integrate_f(x['a'], x['b'], x['N']), axis=1)\n",
    "#            s = pd.concat([ (pd.Series(vwap(df.iloc[i:i+window]), index=[df.index[i+window]])) for i in range(len(df)) ]);\n",
    "#            a = df.iloc[1, df.columns.get_loc('Name')]\n",
    "#            df1.iat[[1, 3, 5], [1, 3]]\n",
    "\n",
    "    df['change'] = 0.\n",
    "    df['label'] = lastlabel = \"-\"\n",
    "    pix = df.columns.get_loc('change') # performance column index\n",
    "    lix = df.columns.get_loc('label')\n",
    "    cix = df.columns.get_loc('close')\n",
    "    win = loss = 0.\n",
    "    for tix in range(1, len(df)) : # tix = time index\n",
    "        last_close = df.iat[tix-1, cix]\n",
    "        delta = (df.iat[tix, cix] - last_close) / last_close * 1000 #  in per mille: 1% == 10\n",
    "        df.iat[tix, pix] = delta \n",
    "        if delta < 0 :\n",
    "            if loss < 0 : # loss monitoring is running\n",
    "                loss += delta\n",
    "            else : # first time bar of decrease period\n",
    "                lossix = tix\n",
    "                loss = delta\n",
    "            if loss < sell_threshold : # reset win monitor because dip exceeded threshold\n",
    "                win = 0.\n",
    "                if lastlabel != \"sell\" : # only one signal without further repeat\n",
    "                    df.iat[lossix, lix] = lastlabel = \"sell\"\n",
    "                    last_close = df.iat[lossix-1, cix]\n",
    "                    df.iat[lossix, pix] = (df.iat[lossix, cix] - last_close) / last_close * 1000 # - transaction_fee\n",
    "                lossix += 1\n",
    "            if win > 0 : # win monitoring is running\n",
    "                win += delta\n",
    "                if win < 0 : # reset win monitor because it is below start price\n",
    "                    win = 0.\n",
    "        elif delta > 0 :\n",
    "            if win > 0 : # win monitoring is running\n",
    "                win += delta\n",
    "            else : # first time bar of increase period\n",
    "                winix = tix\n",
    "                win = delta\n",
    "            if win > buy_threshold : # reset win monitor because dip exceeded threshold\n",
    "                if lastlabel != \"buy\" : # only one signal without further repeat\n",
    "                    df.iat[winix, lix] = lastlabel = \"buy\"\n",
    "                    last_close = df.iat[winix-1, cix]\n",
    "                    df.iat[winix, pix] = (df.iat[winix, cix] - last_close) / last_close * 1000 # - transaction_fee\n",
    "                winix += 1\n",
    "            if loss < 0 : # loss monitoring is running\n",
    "                loss += delta\n",
    "                if loss > 0 :\n",
    "                    loss = 0. # reset loss monitor as it recovered before before triggered sell threshold\n",
    "\n",
    "    print(df[['close', 'label', 'change']])\n",
    "\n",
    "                \n",
    "        \n",
    "\n",
    "def derive_features(df: pd.DataFrame):\n",
    "    \"calc derived candle features in relation to price based on the provided time aggregated dataframe df\"\n",
    "    # price changes in 1/1000\n",
    "    df['height'] = (df['high'] - df['low']) / df['close'] * 1000\n",
    "    df.loc[df['close'] > df['open'], 'top'] = (df['high'] - df['close']) / df['close'] * 1000\n",
    "    df.loc[df['close'] <= df['open'], 'top'] = (df['high'] - df['open']) / df['close'] * 1000\n",
    "    df.loc[df['close'] > df['open'], 'bottom'] = (df['open'] - df['low']) / df['close'] * 1000\n",
    "    df.loc[df['close'] <= df['open'], 'bottom'] = (df['close'] - df['low']) / df['close'] * 1000\n",
    "    return None\n",
    "\n",
    "def time_aggregation(minute_data: pd.DataFrame):\n",
    "    \"\"\"in: dataframe of minute data of a currency pair; \n",
    "       out: dict of dataframes of aggregations with features and targets\"\"\"\n",
    "    aggregations = dict()\n",
    "    time_aggs = list(time_aggregations.keys())\n",
    "    for time_agg in time_aggs:\n",
    "        print(time_agg)\n",
    "        if time_agg is '1T':\n",
    "            df = minute_data\n",
    "            df['volume_change'] = (df['volume']  - df.volume.rolling(vol_base_period).median()) / df.volume.rolling(vol_base_period).median() * 100 # in %\n",
    "        else :\n",
    "            df = pd.DataFrame()\n",
    "            df['close'] = minute_data.close.resample(time_agg, label='right', closed='right').last()\n",
    "            df['high'] = minute_data.high.resample(time_agg, label='right', closed='right').max()\n",
    "            df['low'] = minute_data.low.resample(time_agg, label='right', closed='right').min()\n",
    "            df['open'] = minute_data.open.resample(time_agg, label='right', closed='right').first()\n",
    "            df['volume_change'] = minute_data.volume_change.resample(time_agg, label='right', closed='right').mean()\n",
    "        derive_features(df)\n",
    "        add_period_specific_labels(df)\n",
    "#        print(df)\n",
    "#        print(df[['close', 'high', 'low', 'open', 'volume_change']])\n",
    "        aggregations[time_agg] = df\n",
    "    aggregations['CPC'] = add_asset_summary_labels(aggregations)\n",
    "    return aggregations\n",
    "\n",
    "def next_pairs_level(pairs: pd.DataFrame, level):\n",
    "    \"build pairs of pairs\"\n",
    "    paired = False\n",
    "    first = pairs.loc[pairs.lvl < level] # childs can be on different levels!\n",
    "    if not first.empty :\n",
    "#        print('#first#')\n",
    "#        print(first)\n",
    "        for fp in first.index :\n",
    "            second = first.loc[(first.bts > first.at[fp, 'sts'])] # & (((first.status == 'init') & (first.at[fp, 'status'] == 'init')) != True)] # if both are best == True then pair already exists\n",
    "#            print('#second#')\n",
    "#            print(second)\n",
    "            for sp in second.index :\n",
    "                if first.loc[(first.child1 == fp) & (first.child2 == sp)].empty : # otherwise pair already exists\n",
    "                    paired = True\n",
    "                    pairs = pairs.append(dict([('bts', first.at[fp, 'bts']), ('sts', second.at[sp, 'sts']), ('lvl', level), ('perf', first.at[fp, 'perf'] + second.at[sp, 'perf']), ('child1', fp), ('child2', sp)]), ignore_index=True)\n",
    "#            pairs = pairs.append(dict([('bts',[first.iloc[fix].bts for x in second.index]), ('sts',[second.sts]), \n",
    "#                                  ('lvl',[level for x in second.index]), ('perf',[first.iloc[fix].perf + sp for sp in second.perf]), \n",
    "#                                  ('child1', [first.iloc[fix].index for x in second.index]), ('child2', [x for x in second.index])]), ignore_index=True)\n",
    "        if paired :\n",
    "            pairs = next_pairs_level(pairs, level + 1)\n",
    "#    print('###')\n",
    "#    print(pairs)\n",
    "    return pairs\n",
    "    \n",
    "def calc_performance(row) :\n",
    "#    print('==')\n",
    "#    print(minute_data[['close', 'label']])\n",
    "#    print('--')\n",
    "#    print(row)\n",
    "    return (minute_data.at[row.sts, 'close'] - minute_data.at[row.bts, 'close']) / minute_data.at[row.bts, 'close'] * 1000 - 2 * transaction_fee\n",
    "                     \n",
    "def mark_childs(pairs, bix) :\n",
    "#    print('mark_childs')\n",
    "#    print(pairs)\n",
    "#    print(bix)\n",
    "    pairs.at[bix, 'best'] = True\n",
    "    if pairs.at[bix, 'lvl'] > 0 :\n",
    "        mark_childs(pairs, pairs[bix, 'child1'])\n",
    "        mark_childs(pairs, pairs[bix, 'child2'])\n",
    "\n",
    "\n",
    "def add_asset_summary_labels(aggregations: dict):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    global minute_data\n",
    "    minute_data = aggregations['1T']\n",
    "    max_period = '1T'\n",
    "    for p in iter(aggregations.keys()) :\n",
    "        if aggregations[max_period].index[0].freq < aggregations[p].index[0].freq :\n",
    "            max_period = p\n",
    "#    print('max period'+ aggregations[max_period].index[0].freq)\n",
    "    start_ts = minute_data.index[0]\n",
    "    sell_ixs = aggregations[max_period].loc[aggregations[max_period].label == 'sell']\n",
    "#    pairs = pd.DataFrame(columns=['bts','sts','lvl','best','perf'])\n",
    "    pairs = pd.DataFrame()\n",
    "    for end_ts in sell_ixs.index :\n",
    "        for p in iter(aggregations.keys()) :\n",
    "            buy_sigs = aggregations[p].loc[(aggregations[p].label == 'buy') & (aggregations[p].index >= start_ts) & (aggregations[p].index < end_ts)]\n",
    "#            print (buy_sigs)\n",
    "            for bs in buy_sigs.index :\n",
    "                sell_sigs = aggregations[p].loc[(aggregations[p].label == 'sell') & (aggregations[p].index <= end_ts) & (aggregations[p].index > bs)]\n",
    "#                print (sell_sigs)\n",
    "#                print ('^^^')\n",
    "#                pairs\n",
    "#                print (dict([('bts', [bs for x in sell_sigs.index]), ('sts', [sell_sigs.index]), ('lvl', [0 for x in sell_sigs.index])]))\n",
    "                for s in sell_sigs.index :\n",
    "#                    pairs = pairs.append(dict([('bts', [bs for x in sell_sigs.index]), ('sts', [s for s in sell_sigs.index]), ('lvl', [0 for x in sell_sigs.index])]), ignore_index=True)\n",
    "                    pairs = pairs.append(dict([('bts', bs), ('sts', s), ('lvl', 0)]), ignore_index=True)\n",
    "#        print('---')\n",
    "#        print(minute_data[['close', 'label']])\n",
    "        pairs['perf'] = pairs.apply(calc_performance, axis=1)\n",
    "\n",
    "        # 1st level of pairs created \n",
    "        pairs['best'] = False\n",
    "        pairs = next_pairs_level(pairs, 1) # recursively create all pair levels\n",
    "#        print('-pairs created-')\n",
    "#        print(pairs)\n",
    "#        print(pairs.dtypes)\n",
    "        \n",
    "        # now select only those pairs that are part of the best n paths and continue to work with those\n",
    "        best_perf = pairs.nlargest(max(best_n, len(pairs.index)), 'perf')\n",
    "        st = best_perf.nsmallest(1, 'sts')\n",
    "        start_ts = st.at[st.index[0], 'sts']\n",
    "#        print('-st-')\n",
    "#        print(st)\n",
    "#        print(start_ts)\n",
    "        for bix in best_perf.index :\n",
    "            mark_childs(pairs, bix)\n",
    "#        print('-best_perf-')\n",
    "#        print(pairs)\n",
    "        pairs = pairs.loc[pairs.best] # reduce pairs to best_n path pairs\n",
    "    best_perf = pairs.nlargest(1, 'perf')\n",
    "    pairs['best'] = False\n",
    "    mark_childs(pairs, best_perf.index[0])\n",
    "    print('-pairs marked-')\n",
    "    print(pairs)\n",
    "    pairs = pairs.loc[pairs.best & (pairs.lvl == 0)] # reduce pairs to best_n path pairs on level 0\n",
    "    check_result_consistency(aggregations, pairs)\n",
    "    print('-pairs reduced-')\n",
    "    print(pairs)\n",
    "    cpc_labels = pd.DataFrame(minute_data, columns=['close'])\n",
    "    cpc_labels['label']= '-'\n",
    "    for bix in pairs.index :\n",
    "        if cpc_labels.at[pairs.at[bix, 'bts'], 'label'] != '-' :\n",
    "            print('error buy: inconsistency due to unexpected value instead of hold at timestamp')\n",
    "            print(pairs.at[bix, 'bts'])\n",
    "        else:\n",
    "            cpc_labels.at[pairs.at[bix, 'bts'], 'label'] = 'buy'\n",
    "\n",
    "        if cpc_labels.at[pairs.at[bix, 'sts'], 'label'] != '-' :\n",
    "            print('error sell: inconsistency due to unexpected value instead of hold at timestamp')\n",
    "            print(pairs.at[bix, 'sts'])\n",
    "        else:\n",
    "            cpc_labels.at[pairs.at[bix, 'sts'], 'label'] = 'sell'\n",
    "    print(cpc_labels)\n",
    "    return cpc_labels\n",
    "\n",
    "def check_result_consistency(aggregations, pairs) :\n",
    "    \"consistency checks\"\n",
    "    perf = time_aggregations.copy()\n",
    "    for perf_elem in iter(perf.keys()) :\n",
    "        perf_elem = 0\n",
    "    buy_list = sell_list = list()\n",
    "    best_perf = 0.\n",
    "    tdf = aggregations['1T']\n",
    "    pairs.sort_values(by=['lvl','bts'])\n",
    "    for p in pairs.index :\n",
    "        bts = pairs.at[p, 'bts']\n",
    "        sts = pairs.at[p, 'sts']\n",
    "        check_perf = (tdf.at[sts, 'close'] - tdf.at[bts, 'close']) / tdf.at[bts, 'close'] * 1000 - 2 * transaction_fee\n",
    "        if check_perf > best_perf :\n",
    "            best_perf = check_perf\n",
    "        \n",
    "        if bts >= sts :\n",
    "            print(\"error: intra pair sequence incorrect\")\n",
    "\n",
    "        if pairs.at[p, 'lvl'] == 0 :\n",
    "            if p != pairs.index[0] :\n",
    "                if bts <= laststs :\n",
    "                    print(\"error: level 0 pairs sequence between pairs incorrect\")\n",
    "            laststs = sts\n",
    "            \n",
    "            if bts in buy_list :\n",
    "                print(\"error: double buy in pairs\")\n",
    "            else :\n",
    "                buy_list.append(bts)\n",
    "            if sts in sell_list :\n",
    "                print(\"error: double sell in pairs\")\n",
    "            else :\n",
    "                sell_list.append(sts)\n",
    "        elif pairs.at(p, 'lvl') > 0 :\n",
    "            if (pairs.loc[(pairs.at[p, 'bts'] == pairs.at[pairs.at[p, 'child1'], 'bts'])].empty) or (pairs.loc[(pairs.at[p, 'sts'] == pairs.at[pairs.at[p, 'child2'], 'sts'])].empty) :\n",
    "                print(\"error: can't find consistent childs\")\n",
    "        else : \n",
    "            print(\"error: unexpected level in pairs\")\n",
    "    for agg in iter(aggregations.keys()) :\n",
    "        tdf = aggregations[agg]\n",
    "        lastclose = 0.\n",
    "        sigs = tdf.loc[(tdf.label == 'buy') | (tdf.label == 'sell')]\n",
    "        missed_sell_start = 0\n",
    "        missed_buy_end = -1\n",
    "        for sig in sigs.index :\n",
    "            if sigs.at[sig, 'label'] == 'buy' : \n",
    "                if lastclose == 0. : \n",
    "                    lastclose = sigs.at[sig, 'close']\n",
    "                    missed_buy_end = 1\n",
    "                else :\n",
    "                    missed_buy_end += 1 # buy is following buy                 \n",
    "            elif sigs.at[sig, 'label'] == 'sell' :\n",
    "                if lastclose > 0. : \n",
    "                    perf[agg] = (sigs.at[sig, 'close'] - lastclose) / lastclose * 1000 - 2 * transaction_fee\n",
    "                    lastclose = 0.\n",
    "                    missed_buy_end = 0\n",
    "                else :\n",
    "                    if missed_buy_end < 0 : # no buy signal yet seen\n",
    "                        missed_sell_start += 1\n",
    "                    else :\n",
    "                        pass # sell is following sell\n",
    "            else :\n",
    "                print(\"error: unexpected signal - neither buy nor sell\")\n",
    "        if missed_buy_end > 0 :\n",
    "            print('info: missed buy signals at the end')\n",
    "        if missed_sell_start > 0 :\n",
    "            print('info: missed sell signals at the start')\n",
    "\n",
    "#        bsigs = tdf.loc[(tdf.label == 'buy')]\n",
    "#        check = bsigs.loc[buy_list]\n",
    "#        if (len(bsigs.index) - len(check.index)) > missed_buy_end :\n",
    "#            print(\"error: missing buy signals in pairs\")\n",
    "            \n",
    "#        ssigs = tdf.loc[(tdf.label == 'sell')]\n",
    "#        check = ssigs.loc[sell_list]\n",
    "#        if (len(ssigs.index) - len(check.index)) > missed_sell_start :\n",
    "#            print(\"error: missing sell signals in pairs\")\n",
    "\n",
    "    print('performances')\n",
    "    print(best_perf)\n",
    "    for agg in iter(aggregations.keys()) :\n",
    "        print(agg)\n",
    "        print(perf[agg])\n",
    "        if perf[agg] > best_perf :\n",
    "            print('error: single time aggrgation performance exceeds global best performance')\n",
    "\n",
    "\n",
    "def pair_aggregation(currencies):\n",
    "    \"transform dict of currency dataframes to dict of currency dicts with all time aggregations\"\n",
    "    for pair in currencies:\n",
    "        cur = currencies[pair] # take 1T currency data\n",
    "        currencies[pair] = time_aggregation(cur) # exchange by all required time aggregations\n",
    "    return currencies\n",
    "\n",
    "\n",
    "    \n",
    "def test_features_labels():\n",
    "    \"tests creation of features and labels with artificial data\"\n",
    "    df_len = 21\n",
    "    df = pd.DataFrame(index = pd.date_range('2018-12-28 01:10:00', periods=df_len, freq='T'))\n",
    "    cl = 100.\n",
    "    cl_delta = 1.1 / 5\n",
    "    df['open'] = 0.\n",
    "    df['high'] = 0.\n",
    "    df['low'] = 0.\n",
    "    df['close'] = 0.\n",
    "    df['volume'] = 10.\n",
    "    \n",
    "    for tf in range( 0, df_len) : \n",
    "        df.iloc[tf] = [cl- 1., cl + 0.5, cl - 2., cl, 10.]\n",
    "        if tf <= 4 : #raise above 1% to trigger buy\n",
    "            cl += cl_delta\n",
    "        elif tf <= 5 : # fall -0.2% to trigger sell but only on minute basis\n",
    "            cl -= cl_delta\n",
    "            df.iloc[tf, 4] = 20.\n",
    "        elif tf <= 9 : # raise above 1% with dip above -0.2% to not raise a trigger\n",
    "            cl += cl_delta\n",
    "        elif tf <= 13 : # raise above 1% with dip above -0.2% to not raise a trigger\n",
    "            cl -= cl_delta / 4\n",
    "        elif tf <= 30 : # raise above 1% with dip above -0.2% to not raise a trigger\n",
    "            cl += cl_delta\n",
    "                \n",
    "    currencies = dict()\n",
    "    currencies['tst_usdt'] = df\n",
    "    return currencies\n",
    "\n",
    "\n",
    "aggregate_currencies = pair_aggregation(test_features_labels())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalyst Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from catalyst.utils.run_algo import run_algorithm\n",
    "from catalyst.protocol import BarData\n",
    "\n",
    "def initialize(context):\n",
    "    context.handle_count = 0\n",
    "    print(\"init\")\n",
    "\n",
    "\n",
    "def handle_data(context, data: BarData):\n",
    "    \n",
    "    if (context.handle_count < 1):\n",
    "        catalyst2picklepandas(context, data)\n",
    "#        feature_normalize(fn)\n",
    "\n",
    "        context.handle_count = context.handle_count + 1\n",
    "    return None\n",
    "        \n",
    "\n",
    "def analyze(context=None, results=None):\n",
    "    pass\n",
    "\n",
    "start = datetime(2018, 12, 18, 0, 0, 0, 0, pytz.utc)\n",
    "# end = datetime(2018, 9, 24, 0, 0, 0, 0, pytz.utc)\n",
    "end = datetime(2018, 12, 18, 0, 0, 0, 0, pytz.utc)\n",
    "results = run_algorithm(initialize=initialize,\n",
    "                        handle_data=handle_data,\n",
    "                        analyze=analyze,\n",
    "                        start=start,\n",
    "                        end=end,\n",
    "                        exchange_name='binance',\n",
    "                        data_frequency='minute',\n",
    "                        quote_currency ='usdt',\n",
    "                        capital_base=10000 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_asset_summary_labels(aggregations: dict):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    df_1t = aggregations['1T']\n",
    "    ix_1t = aggregations['1T'].index\n",
    "    res_keys = ['freqkey', 'buyix', 'sellix', 'performance', 'status']\n",
    "    res = pd.DataFrame(columns=res_keys)\n",
    "    res = res.append(pd.DataFrame(dict(zip(res.columns, [['a'], ['b'], ['c'], [50.], [True]]))), ignore_index=True)\n",
    "\n",
    "    index_set = dict(zip(aggregations.keys, [0 for x in aggregations.keys]))\n",
    "    for ix1t in range(0, len(ix_1t)) : # tix = timestamp index of 1T index\n",
    "        for tkey in aggregations.keys :\n",
    "            df = aggregations[tkey]\n",
    "            if index_set[tkey] < len(df.index) :\n",
    "                if ix_1t[ix1t] == df.index[index_set[tkey]] : # common timestamp\n",
    "                    rdf = df.iloc[index_set[tkey]] # work with that row\n",
    "                    if rdf.label == \"buy\" :\n",
    "                        res = res.append(pd.DataFrame({'freqkey':[tkey], 'buyix':[index_set[tkey]], 'status':['open']}), ignore_index=True)\n",
    "                    elif rdf.label == \"sell\" :\n",
    "                        if not res.loc[(res.freqkey == tkey) & (res.status == 'open')].empty :\n",
    "                            res.loc[(res.freqkey == tkey) & (res.status == 'open'), ['sellix', 'status']] = [index_set[tkey], 'close']\n",
    "                    index_set[tkey]+= 1\n",
    "    #now go through the list of pairs and remove all open orphans and create for closed pairs a pair of pair list that can be combined from an sequence perspective\n",
    "    res = res.loc[(res.freqkey == tkey) & (res.status == 'close')]\n",
    "    res_buy = res.sort_values(by=['buyix'])\n",
    "    res_sell = res.sort_values(by=['sellix'])\n",
    "    # calculate performance only for possible pathes\n",
    "    perf = df_1t.iloc[ix1t]['performance'] # open: stepwise adapt performance or calculate at sell with roll up call?\n",
    "    perf -= transaction_fee\n",
    "    # open: add 'res' to aggregations                 \n",
    "    return res\n",
    "\n",
    "\n",
    "def combine_catalyst_data(currencies):\n",
    "    \"unused: receive a dictionary of dataframes and returns a single multiindex dataframe\"\n",
    "    combined_curr = None\n",
    "    cindex = []\n",
    "    for pair in currencies:\n",
    "        cindex.clear()\n",
    "        datakeys = [dkey for dkey in currencies[pair].keys()]\n",
    "        currkeys = [pair for x in datakeys]\n",
    "        cindex = [currkeys, datakeys]\n",
    "        \n",
    "        #simply set the column attribute to the new index ti get a multilevel index\n",
    "        currencies[pair].columns = pd.MultiIndex.from_arrays(cindex, names=['currency', 'candle'])\n",
    "#        print(currencies[pair])\n",
    "    combined_curr = currencies['xrp_usdt'].merge(currencies['btc_usdt'], how='outer', \n",
    "                                                 left_index=True, right_index=True)\n",
    "    print(combined_curr)\n",
    "    return combined_curr\n",
    "\n",
    "\n",
    "def add_asset_summary_labels(aggregations: dict):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    time_aggs = list(aggregations.keys())\n",
    "    time_agg = '1T'\n",
    "    print(time_agg)\n",
    "    df = aggregations[time_agg]\n",
    "    labeldf = df[['buy_tg', 'sell_tg', 'max_profit']]\n",
    "    labeldf.columns=['buy_tg_' + time_agg, 'sell_tg_' + time_agg, 'max_profit_' + time_agg]\n",
    "    for time_agg in time_aggs:\n",
    "        if time_agg != '1T':\n",
    "            print(time_agg)\n",
    "            df = aggregations[time_agg]\n",
    "            df_extract  = df[['buy_tg', 'sell_tg', 'max_profit']]\n",
    "            df_extract = df_extract.resample('1T').bfill()\n",
    "            df_extract.columns=['buy_tg_' + time_agg, 'sell_tg_' + time_agg, 'max_profit_' + time_agg]\n",
    "            labeldf = labeldf.merge(df_extract, how='left', left_index=True, right_index=True)\n",
    "        print(labeldf)\n",
    "    return labeldf\n",
    "\n",
    "def add_period_specific_labels(df: pd.DataFrame):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    df['sell_tg'] = df['dip_tg'] = df['buy_tg'] = 0\n",
    "    df['loc_max'] = df['buy_max'] = df.close\n",
    "    for ltg in range(-1, -(20), -1) : # tg = time gap; max time gap 4h = 60*4 T(minutes)\n",
    "        df['loss_check'] = (df.close.tshift(ltg) - df.loc_max) / df.loc_max * 1000 #  in per mille: 1% == 10\n",
    "        df['max_profit'] = (df.close.tshift(ltg) - df.close) / df.close * 1000 #  in per mille: 1% == 10\n",
    "\n",
    "        # calculate sell signals\n",
    "        df.loc[(df.max_profit > 0) & (df.sell_tg == 0), 'sell_tg'] = -ltg # equals no loss from start \n",
    "        df.loc[(df.max_profit < sell_threshold) & (df.sell_tg == 0), 'sell_tg'] = ltg # equals < -0.2% loss from start \n",
    "\n",
    "        # calculate buy signals\n",
    "        df.loc[(df.loss_check > 0) & (df.dip_tg == 0), 'loc_max'] = df.close.tshift(ltg) # note new high in other\n",
    "        df.loc[(df.loss_check < sell_threshold) & (df.dip_tg == 0), 'dip_tg'] = ltg # equals < -0.2% loss from last high\n",
    "        df.loc[(df.max_profit > buy_threshold) & (df.max_profit > ((df.buy_max - df.close) / df.close * 1000)) & (df.dip_tg == 0), 'buy_tg'] = ltg\n",
    "        df.loc[(df.max_profit > buy_threshold) & (df.max_profit > ((df.buy_max - df.close) / df.close * 1000)) & (df.dip_tg == 0), 'buy_max'] = df.close.tshift(ltg)\n",
    "    df['max_profit'] = 0.\n",
    "#    df.loc[(df.dip_tg < df.buy_tg) & (df.buy_tg != 0), 'dip_tg'] = 0 # if sell event happens later than buy event then remove sell signal\n",
    "    df.loc[(df.buy_tg != 0), 'max_profit'] = ((df.buy_max - df.close) / df.close * 1000) # in per mille: 1% == 10\n",
    "\n",
    "    # now cleanup    \n",
    "    df.pop('loss_check')\n",
    "    df.pop('loc_max')\n",
    "    df.pop('buy_max')\n",
    "    df.pop('dip_tg')\n",
    "#    df.pop('max_profit') # max_profit is not needed anymore but handy to cross check results\n",
    "\n",
    "    df['change'] =  df.close - df.close.tshift(1) # performance without fees\n",
    "    df['label'] = \"hold\"\n",
    "    df.loc[(df.sell_tg < 0), 'label'] = \"sell\"\n",
    "    df.loc[(df.buy_tg < 0), 'label'] = \"buy\"\n",
    "\n",
    "    #        print(df[['close', 'sell_tg', 'buy_tg', 'loc_max', 'buy_max', 'max_profit']])\n",
    "    print(df[['close', 'sell_tg', 'buy_tg', 'max_profit']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_labels(df):\n",
    "    \"target = achieved if improvement > 1% with intermediate Close loss not lower than start Close\"\n",
    "    # df.tg = 0 means not yet checked; < 0 is negative tg of delta < 0; > 0 is tg with best improvement > 1%\n",
    "    df['tg'] = ltg = 0\n",
    "    df['change'] = 0.\n",
    "    df['other'] = df.close\n",
    "    delta = 0.\n",
    "    for ltg in range(-1, -5, -1) : # tg = time gap; max time gap 4h = 60*4 T(minutes)\n",
    "        loss_check = (df.close.tshift(ltg) - df.other) / df.other * 1000 # delta in per mille: 1% == 10\n",
    "        delta = (df.close.tshift(ltg) - df.close) / df.close * 1000 # delta in per mille: 1% == 10\n",
    "        df.loc[(loss_check > 0) & (df.tg == 0), 'other'] = df.close.tshift(ltg) # note new high in other\n",
    "        df.loc[(loss_check < -2) & (df.tg == 0), ['tg', 'change']] = [ltg, delta] # equals < -0.2% loss from last high\n",
    "# reports error: ValueError: setting an array element with a sequence.\n",
    "# code snippet shows it should work\n",
    "\n",
    "        df.loc[(delta < 0) & (df.tg == 0), ['tg', 'change']] = [ltg, delta] # equals any loss from start\n",
    "# doesn't work: df.loc[(delta > 1) & (df.close.tshift(ltg) > df.close.tshift(df.tg)) & (df.tg >= 0), 'tg'] = ltg\n",
    "        df.loc[(delta > 10) & (df.tg == 0), ['tg', 'change']] = [-ltg, delta]\n",
    "\n",
    "        df.loc[(df.tg == ltg) | (df.tg == -ltg), 'change'] = delta\n",
    "# reports error: ValueError: Must have equal len keys and value when setting with an iterable\n",
    "# although it works in a previos iteration with 1T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
