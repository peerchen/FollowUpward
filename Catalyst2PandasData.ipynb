{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "catalyst ingest-exchange -x binance -i xrp_usdt -f minute\n",
    "catalyst ingest-exchange -x binance -i btc_usdt -f minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start terminal from anaconda/environments/catalyst\n",
    "# in terminal the catalyst environment should be active, which can be checked by conda info --all\n",
    "# jupyter lab work doesn't work as it doesn't switch to the catalyst environment\n",
    "# start jupyter notebook by: jupyter notebook\n",
    "%load_ext catalyst\n",
    "# required to activate catalyst magic words \n",
    "\n",
    "\n",
    "# Setup matplotlib to display graphs inline in this Notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Catalyst historic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "from catalyst.api import symbol, symbols\n",
    "from catalyst.protocol import BarData\n",
    "cur_cand = ['xrp_usdt', 'btc_usdt'] \n",
    "data_keys = ['open', 'high', 'low', 'close', 'volume'] # , 'price'\n",
    "\n",
    "\n",
    "def catalyst2picklepandas(context, data: BarData):\n",
    "    \"reads catalyst data for trading pairs and stores them in a testfile for subsequent usage\"\n",
    "    test = currencies = dict()\n",
    "    filename = os.getcwd() + '/df-test.pydata'\n",
    "\n",
    "    for pair in cur_cand:\n",
    "        current = data.history(symbol(pair), data_keys, 239*24*60, '1T')\n",
    "        currencies[pair] = current\n",
    "        print(current.head())\n",
    "        print(current.tail())\n",
    "\n",
    "    print(\"got catalyst history data\")\n",
    "    df_f = open(filename, 'wb')\n",
    "    pickle.dump(currencies, df_f)\n",
    "    df_f.close()\n",
    "    print(\"data frame is written\")\n",
    "#    df_f = open(filename, 'rb')\n",
    "#    test = pickle.load(df_f)\n",
    "#    df_f.close()\n",
    "#    print(test)\n",
    "    return None\n",
    "\n",
    "def feature_normalize(filename: str):\n",
    "    currencies = dict()\n",
    "    df_f = open(filename, 'rb')\n",
    "    currencies = pickle.load(df_f)\n",
    "    df_f.close()\n",
    "#    combined_curr = combine_catalyst_data(currencies)\n",
    "    aggregate_currencies = pair_aggregation(currencies)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1T\n",
      "                       close label    change\n",
      "2018-12-28 01:10:00  100.000  hold  0.000000\n",
      "2018-12-28 01:11:00  100.220   buy  1.200000\n",
      "2018-12-28 01:12:00  100.440  hold  2.195171\n",
      "2018-12-28 01:13:00  100.660  hold  2.190362\n",
      "2018-12-28 01:14:00  100.880  hold  2.185575\n",
      "2018-12-28 01:15:00  101.100  hold  2.180809\n",
      "2018-12-28 01:16:00  100.880  sell -3.176063\n",
      "2018-12-28 01:17:00  101.100  hold  2.180809\n",
      "2018-12-28 01:18:00  101.320  hold  2.176063\n",
      "2018-12-28 01:19:00  101.540  hold  2.171338\n",
      "2018-12-28 01:20:00  101.760  hold  2.166634\n",
      "2018-12-28 01:21:00  101.705  hold -0.540487\n",
      "2018-12-28 01:22:00  101.650  hold -0.540780\n",
      "2018-12-28 01:23:00  101.595  hold -0.541072\n",
      "2018-12-28 01:24:00  101.540  hold -0.541365\n",
      "2018-12-28 01:25:00  101.760   buy  1.166634\n",
      "2018-12-28 01:26:00  101.980  hold  2.161950\n",
      "2018-12-28 01:27:00  102.200  hold  2.157286\n",
      "2018-12-28 01:28:00  102.420  hold  2.152642\n",
      "2018-12-28 01:29:00  102.640  hold  2.148018\n",
      "2018-12-28 01:30:00  102.860  hold  2.143414\n",
      "2T\n",
      "                      close label    change\n",
      "2018-12-28 01:10:00  100.00  hold  0.000000\n",
      "2018-12-28 01:12:00  100.44   buy  3.400000\n",
      "2018-12-28 01:14:00  100.88  hold  4.380725\n",
      "2018-12-28 01:16:00  100.88  hold  0.000000\n",
      "2018-12-28 01:18:00  101.32  hold  4.361618\n",
      "2018-12-28 01:20:00  101.76  hold  4.342677\n",
      "2018-12-28 01:22:00  101.65  sell -2.080975\n",
      "2018-12-28 01:24:00  101.54  hold -1.082145\n",
      "2018-12-28 01:26:00  101.98   buy  3.333268\n",
      "2018-12-28 01:28:00  102.42  hold  4.314571\n",
      "2018-12-28 01:30:00  102.86  hold  4.296036\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "time_aggregations = {'1T':4, '2T':4} # , '4T':4\n",
    "vol_base_period = '1D'\n",
    "sell_threshold = -2 # in per mille\n",
    "buy_threshold = 10 # in per mille\n",
    "transaction_fee = 1 # in per mille, i.e. 0,1%\n",
    "\n",
    "def check_tag(tg, ltg):\n",
    "    return abs(tg) == abs(ltg)\n",
    "    \n",
    "def add_period_specific_labels(df: pd.DataFrame):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "#            df.apply(lambda x: integrate_f(x['a'], x['b'], x['N']), axis=1)\n",
    "#            s = pd.concat([ (pd.Series(vwap(df.iloc[i:i+window]), index=[df.index[i+window]])) for i in range(len(df)) ]);\n",
    "#            a = df.iloc[1, df.columns.get_loc('Name')]\n",
    "#            df1.iat[[1, 3, 5], [1, 3]]\n",
    "\n",
    "    df['change'] = 0.\n",
    "    df['label'] = lastlasbel = \"hold\"\n",
    "    pix = df.columns.get_loc('change') # performance column index\n",
    "    lix = df.columns.get_loc('label')\n",
    "    cix = df.columns.get_loc('close')\n",
    "    win = loss = 0.\n",
    "    df.iloc[0, [lix, pix]] = [\"hold\", 0.]\n",
    "    for tix in range(1, len(df)) : # tix = time index\n",
    "        last_close = df.iat[tix-1, cix]\n",
    "        delta = (df.iat[tix, cix] - last_close) / last_close * 1000 #  in per mille: 1% == 10\n",
    "        df.iat[tix, pix] = delta \n",
    "        if delta < 0 :\n",
    "            if loss < 0 : # loss monitoring is running\n",
    "                loss += delta\n",
    "            else : # first time bar of decrease period\n",
    "                lossix = tix\n",
    "                loss = delta\n",
    "            if loss < sell_threshold : # reset win monitor because dip exceeded threshold\n",
    "                win = 0.\n",
    "                if lastlasbel != \"sell\" : # only one signal without further repeat\n",
    "                    df.iat[lossix, lix] = lastlasbel = \"sell\"\n",
    "                    last_close = df.iat[lossix-1, cix]\n",
    "                    df.iat[lossix, pix] = (df.iat[lossix, cix] - last_close) / last_close * 1000 - transaction_fee\n",
    "                lossix += 1\n",
    "            if win > 0 : # win monitoring is running\n",
    "                win += delta\n",
    "                if win < 0 : # reset win monitor because it is below start price\n",
    "                    win = 0.\n",
    "        elif delta > 0 :\n",
    "            if win > 0 : # win monitoring is running\n",
    "                win += delta\n",
    "            else : # first time bar of increase period\n",
    "                winix = tix\n",
    "                win = delta\n",
    "            if win > buy_threshold : # reset win monitor because dip exceeded threshold\n",
    "                if lastlasbel != \"buy\" : # only one signal without further repeat\n",
    "                    df.iat[winix, lix] = lastlasbel = \"buy\"\n",
    "                    last_close = df.iat[winix-1, cix]\n",
    "                    df.iat[winix, pix] = (df.iat[winix, cix] - last_close) / last_close * 1000 - transaction_fee\n",
    "                winix += 1\n",
    "            if loss < 0 : # loss monitoring is running\n",
    "                loss += delta\n",
    "                if loss > 0 :\n",
    "                    loss = 0. # reset loss monitor as it recovered before before triggered sell threshold\n",
    "\n",
    "    print(df[['close', 'label', 'change']])\n",
    "\n",
    "                \n",
    "        \n",
    "\n",
    "def derive_features(df: pd.DataFrame):\n",
    "    \"calc derived candle features in relation to price based on the provided time aggregated dataframe df\"\n",
    "    # price changes in 1/1000\n",
    "    df['height'] = (df['high'] - df['low']) / df['close'] * 1000\n",
    "    df.loc[df['close'] > df['open'], 'top'] = (df['high'] - df['close']) / df['close'] * 1000\n",
    "    df.loc[df['close'] <= df['open'], 'top'] = (df['high'] - df['open']) / df['close'] * 1000\n",
    "    df.loc[df['close'] > df['open'], 'bottom'] = (df['open'] - df['low']) / df['close'] * 1000\n",
    "    df.loc[df['close'] <= df['open'], 'bottom'] = (df['close'] - df['low']) / df['close'] * 1000\n",
    "    return None\n",
    "\n",
    "def time_aggregation(minute_data: pd.DataFrame):\n",
    "    \"\"\"in: dataframe of minute data of a currency pair; \n",
    "       out: dict of dataframes of aggregations with features and targets\"\"\"\n",
    "    aggregations = dict()\n",
    "    time_aggs = list(time_aggregations.keys())\n",
    "    for time_agg in time_aggs:\n",
    "        print(time_agg)\n",
    "        if time_agg is '1T':\n",
    "            df = minute_data\n",
    "            df['volume_change'] = (df['volume']  - df.volume.rolling(vol_base_period).median()) / df.volume.rolling(vol_base_period).median() * 100 # in %\n",
    "        else :\n",
    "            df = pd.DataFrame()\n",
    "            df['close'] = minute_data.close.resample(time_agg, label='right', closed='right').last()\n",
    "            df['high'] = minute_data.high.resample(time_agg, label='right', closed='right').max()\n",
    "            df['low'] = minute_data.low.resample(time_agg, label='right', closed='right').min()\n",
    "            df['open'] = minute_data.open.resample(time_agg, label='right', closed='right').first()\n",
    "            df['volume_change'] = minute_data.volume_change.resample(time_agg, label='right', closed='right').mean()\n",
    "        derive_features(df)\n",
    "        add_period_specific_labels(df)\n",
    "#        print(df)\n",
    "#        print(df[['close', 'high', 'low', 'open', 'volume_change']])\n",
    "        aggregations[time_agg] = df\n",
    "#    aggregations['asset_summary'] = add_asset_summary_labels(aggregations)\n",
    "    return aggregations\n",
    "\n",
    "def add_asset_summary_labels(aggregations: dict):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    time_aggs = list(aggregations.keys())\n",
    "    time_agg = '1T'\n",
    "    print(time_agg)\n",
    "    df = aggregations[time_agg]\n",
    "    if True :\n",
    "        \n",
    "        ldf = df[['buy_tg', 'sell_tg']]\n",
    "\n",
    "    #    ldf['cpc_label'] = pd.Series([\"sell\", \"hold\", \"buy\", \"inconsistent\"], dtype = \"category\", index = ldf.index)\n",
    "        ldf['cpc_label'] = \"hold\"\n",
    "        ldf.loc[ldf['buy_tg'] < 0, 'cpc_label'] = \"buy\"\n",
    "        ldf.loc[ldf['sell_tg'] < 0, 'cpc_label'] = \"sell\"\n",
    "        ldf.loc[(ldf['buy_tg'] < 0) & (ldf['sell_tg'] < 0), 'cpc_label'] = \"inconsistent\"\n",
    "\n",
    "        for time_agg in time_aggs:\n",
    "            if time_agg != '1T':\n",
    "                print(time_agg)\n",
    "                df = aggregations[time_agg]\n",
    "                df_extract  = df[['buy_tg', 'sell_tg']]\n",
    "                df_extract = df_extract.resample('1T').bfill()\n",
    "\n",
    "                ldf = ldf.merge(df_extract, how='left', left_index=True, right_index=True)\n",
    "                ldf.loc[(ldf['buy_tg'] < 0)  & (ldf['cpc_label'] != \"sell\"), 'cpc_label'] = \"buy\"\n",
    "                ldf.loc[(ldf['sell_tg'] < 0) & (ldf['cpc_label'] != \"buy\"), 'cpc_label'] = \"sell\"\n",
    "                ldf.loc[(ldf['buy_tg'] < 0)  & (ldf['sell_tg'] < 0), 'cpc_label'] = \"inconsistent\"\n",
    "            print(ldf)\n",
    "            ldf.pop('buy_tg')\n",
    "            ldf.pop('sell_tg')\n",
    "    else :\n",
    "        \n",
    "        ldf = df[['buy_tg', 'sell_tg', 'max_profit']]\n",
    "        ldf.columns=['buy_tg_' + time_agg, 'sell_tg_' + time_agg, 'max_profit_' + time_agg]\n",
    "        for time_agg in time_aggs:\n",
    "            if time_agg != '1T':\n",
    "                print(time_agg)\n",
    "                df = aggregations[time_agg]\n",
    "                df_extract  = df[['buy_tg', 'sell_tg', 'max_profit']]\n",
    "                df_extract = df_extract.resample('1T').bfill()\n",
    "                df_extract.columns=['buy_tg_' + time_agg, 'sell_tg_' + time_agg, 'max_profit_' + time_agg]\n",
    "                ldf = ldf.merge(df_extract, how='left', left_index=True, right_index=True)\n",
    "            print(ldf)\n",
    "    return ldf\n",
    "\n",
    "def pair_aggregation(currencies):\n",
    "    \"transform dict of currency dataframes to dict of currency dicts with all time aggregations\"\n",
    "    for pair in currencies:\n",
    "        cur = currencies[pair] # take 1T currency data\n",
    "        currencies[pair] = time_aggregation(cur) # exchange by all required time aggregations\n",
    "    return currencies\n",
    "\n",
    "\n",
    "    \n",
    "def test_features_labels():\n",
    "    \"tests creation of features and labels with artificial data\"\n",
    "    df_len = 21\n",
    "    df = pd.DataFrame(index = pd.date_range('2018-12-28 01:10:00', periods=df_len, freq='T'))\n",
    "    cl = 100.\n",
    "    cl_delta = 1.1 / 5\n",
    "    df['open'] = 0.\n",
    "    df['high'] = 0.\n",
    "    df['low'] = 0.\n",
    "    df['close'] = 0.\n",
    "    df['volume'] = 10.\n",
    "    \n",
    "    for tf in range( 0, df_len) : \n",
    "        df.iloc[tf] = [cl- 1., cl + 0.5, cl - 2., cl, 10.]\n",
    "        if tf <= 4 : #raise above 1% to trigger buy\n",
    "            cl += cl_delta\n",
    "        elif tf <= 5 : # fall -0.2% to trigger sell but only on minute basis\n",
    "            cl -= cl_delta\n",
    "            df.iloc[tf, 4] = 20.\n",
    "        elif tf <= 9 : # raise above 1% with dip above -0.2% to not raise a trigger\n",
    "            cl += cl_delta\n",
    "        elif tf <= 13 : # raise above 1% with dip above -0.2% to not raise a trigger\n",
    "            cl -= cl_delta / 4\n",
    "        elif tf <= 30 : # raise above 1% with dip above -0.2% to not raise a trigger\n",
    "            cl += cl_delta\n",
    "                \n",
    "    currencies = dict()\n",
    "    currencies['tst_usdt'] = df\n",
    "    return currencies\n",
    "\n",
    "\n",
    "aggregate_currencies = pair_aggregation(test_features_labels())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1T\n",
    "                       close  sell_tg  buy_tg  max_profit\n",
    "2018-12-28 01:10:00  100.000        1      -5   11.000000\n",
    "2018-12-28 01:11:00  100.220        1       0    0.000000\n",
    "2018-12-28 01:12:00  100.440        1       0    0.000000\n",
    "2018-12-28 01:13:00  100.660        1       0    0.000000\n",
    "2018-12-28 01:14:00  100.880        1       0    0.000000\n",
    "2018-12-28 01:15:00  101.100       -1       0    0.000000\n",
    "2018-12-28 01:16:00  100.880        1       0    0.000000\n",
    "2018-12-28 01:17:00  101.100        1       0    0.000000\n",
    "2018-12-28 01:18:00  101.320        1       0    0.000000\n",
    "2018-12-28 01:19:00  101.540        1       0    0.000000\n",
    "2018-12-28 01:20:00  101.760       -4       0    0.000000\n",
    "2018-12-28 01:21:00  101.705        4      -9   11.356374\n",
    "2018-12-28 01:22:00  101.650        3      -8   11.903591\n",
    "2018-12-28 01:23:00  101.595        2      -7   12.451400\n",
    "2018-12-28 01:24:00  101.540        1      -6   12.999803\n",
    "2018-12-28 01:25:00  101.760        1      -5   10.809748\n",
    "2018-12-28 01:26:00  101.980        1       0    0.000000\n",
    "2018-12-28 01:27:00  102.200        1       0    0.000000\n",
    "2018-12-28 01:28:00  102.420        1       0    0.000000\n",
    "2018-12-28 01:29:00  102.640        1       0    0.000000\n",
    "2018-12-28 01:30:00  102.860        0       0    0.000000\n",
    "2T\n",
    "                      close  sell_tg  buy_tg  max_profit\n",
    "2018-12-28 01:10:00  100.00        1      -5   17.600000\n",
    "2018-12-28 01:12:00  100.44        1      -4   13.142174\n",
    "2018-12-28 01:14:00  100.88        2       0    0.000000\n",
    "2018-12-28 01:16:00  100.88        1       0    0.000000\n",
    "2018-12-28 01:18:00  101.32        1       0    0.000000\n",
    "2018-12-28 01:20:00  101.76       -2       0    0.000000\n",
    "2018-12-28 01:22:00  101.65        2      -4   11.903591\n",
    "2018-12-28 01:24:00  101.54        1      -3   12.999803\n",
    "2018-12-28 01:26:00  101.98        1       0    0.000000\n",
    "2018-12-28 01:28:00  102.42        1       0    0.000000\n",
    "2018-12-28 01:30:00  102.86        0       0    0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalyst Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from catalyst.utils.run_algo import run_algorithm\n",
    "from catalyst.protocol import BarData\n",
    "\n",
    "def initialize(context):\n",
    "    context.handle_count = 0\n",
    "    print(\"init\")\n",
    "\n",
    "\n",
    "def handle_data(context, data: BarData):\n",
    "    \n",
    "    if (context.handle_count < 1):\n",
    "        catalyst2picklepandas(context, data)\n",
    "#        feature_normalize(fn)\n",
    "\n",
    "        context.handle_count = context.handle_count + 1\n",
    "    return None\n",
    "        \n",
    "\n",
    "def analyze(context=None, results=None):\n",
    "    pass\n",
    "\n",
    "start = datetime(2018, 12, 18, 0, 0, 0, 0, pytz.utc)\n",
    "# end = datetime(2018, 9, 24, 0, 0, 0, 0, pytz.utc)\n",
    "end = datetime(2018, 12, 18, 0, 0, 0, 0, pytz.utc)\n",
    "results = run_algorithm(initialize=initialize,\n",
    "                        handle_data=handle_data,\n",
    "                        analyze=analyze,\n",
    "                        start=start,\n",
    "                        end=end,\n",
    "                        exchange_name='binance',\n",
    "                        data_frequency='minute',\n",
    "                        quote_currency ='usdt',\n",
    "                        capital_base=10000 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_catalyst_data(currencies):\n",
    "    \"unused: receive a dictionary of dataframes and returns a single multiindex dataframe\"\n",
    "    combined_curr = None\n",
    "    cindex = []\n",
    "    for pair in currencies:\n",
    "        cindex.clear()\n",
    "        datakeys = [dkey for dkey in currencies[pair].keys()]\n",
    "        currkeys = [pair for x in datakeys]\n",
    "        cindex = [currkeys, datakeys]\n",
    "        \n",
    "        #simply set the column attribute to the new index ti get a multilevel index\n",
    "        currencies[pair].columns = pd.MultiIndex.from_arrays(cindex, names=['currency', 'candle'])\n",
    "#        print(currencies[pair])\n",
    "    combined_curr = currencies['xrp_usdt'].merge(currencies['btc_usdt'], how='outer', \n",
    "                                                 left_index=True, right_index=True)\n",
    "    print(combined_curr)\n",
    "    return combined_curr\n",
    "\n",
    "\n",
    "def add_asset_summary_labels(aggregations: dict):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    time_aggs = list(aggregations.keys())\n",
    "    time_agg = '1T'\n",
    "    print(time_agg)\n",
    "    df = aggregations[time_agg]\n",
    "    labeldf = df[['buy_tg', 'sell_tg', 'max_profit']]\n",
    "    labeldf.columns=['buy_tg_' + time_agg, 'sell_tg_' + time_agg, 'max_profit_' + time_agg]\n",
    "    for time_agg in time_aggs:\n",
    "        if time_agg != '1T':\n",
    "            print(time_agg)\n",
    "            df = aggregations[time_agg]\n",
    "            df_extract  = df[['buy_tg', 'sell_tg', 'max_profit']]\n",
    "            df_extract = df_extract.resample('1T').bfill()\n",
    "            df_extract.columns=['buy_tg_' + time_agg, 'sell_tg_' + time_agg, 'max_profit_' + time_agg]\n",
    "            labeldf = labeldf.merge(df_extract, how='left', left_index=True, right_index=True)\n",
    "        print(labeldf)\n",
    "    return labeldf\n",
    "\n",
    "def add_period_specific_labels(df: pd.DataFrame):\n",
    "    \"target = achieved if improvement > 1% without intermediate loss of more than 0.2%\"\n",
    "\n",
    "    df['sell_tg'] = df['dip_tg'] = df['buy_tg'] = 0\n",
    "    df['loc_max'] = df['buy_max'] = df.close\n",
    "    for ltg in range(-1, -(20), -1) : # tg = time gap; max time gap 4h = 60*4 T(minutes)\n",
    "        df['loss_check'] = (df.close.tshift(ltg) - df.loc_max) / df.loc_max * 1000 #  in per mille: 1% == 10\n",
    "        df['max_profit'] = (df.close.tshift(ltg) - df.close) / df.close * 1000 #  in per mille: 1% == 10\n",
    "\n",
    "        # calculate sell signals\n",
    "        df.loc[(df.max_profit > 0) & (df.sell_tg == 0), 'sell_tg'] = -ltg # equals no loss from start \n",
    "        df.loc[(df.max_profit < sell_threshold) & (df.sell_tg == 0), 'sell_tg'] = ltg # equals < -0.2% loss from start \n",
    "\n",
    "        # calculate buy signals\n",
    "        df.loc[(df.loss_check > 0) & (df.dip_tg == 0), 'loc_max'] = df.close.tshift(ltg) # note new high in other\n",
    "        df.loc[(df.loss_check < sell_threshold) & (df.dip_tg == 0), 'dip_tg'] = ltg # equals < -0.2% loss from last high\n",
    "        df.loc[(df.max_profit > buy_threshold) & (df.max_profit > ((df.buy_max - df.close) / df.close * 1000)) & (df.dip_tg == 0), 'buy_tg'] = ltg\n",
    "        df.loc[(df.max_profit > buy_threshold) & (df.max_profit > ((df.buy_max - df.close) / df.close * 1000)) & (df.dip_tg == 0), 'buy_max'] = df.close.tshift(ltg)\n",
    "    df['max_profit'] = 0.\n",
    "#    df.loc[(df.dip_tg < df.buy_tg) & (df.buy_tg != 0), 'dip_tg'] = 0 # if sell event happens later than buy event then remove sell signal\n",
    "    df.loc[(df.buy_tg != 0), 'max_profit'] = ((df.buy_max - df.close) / df.close * 1000) # in per mille: 1% == 10\n",
    "\n",
    "    # now cleanup    \n",
    "    df.pop('loss_check')\n",
    "    df.pop('loc_max')\n",
    "    df.pop('buy_max')\n",
    "    df.pop('dip_tg')\n",
    "#    df.pop('max_profit') # max_profit is not needed anymore but handy to cross check results\n",
    "\n",
    "    df['change'] =  df.close - df.close.tshift(1) # performance without fees\n",
    "    df['label'] = \"hold\"\n",
    "    df.loc[(df.sell_tg < 0), 'label'] = \"sell\"\n",
    "    df.loc[(df.buy_tg < 0), 'label'] = \"buy\"\n",
    "\n",
    "    #        print(df[['close', 'sell_tg', 'buy_tg', 'loc_max', 'buy_max', 'max_profit']])\n",
    "    print(df[['close', 'sell_tg', 'buy_tg', 'max_profit']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_labels(df):\n",
    "    \"target = achieved if improvement > 1% with intermediate Close loss not lower than start Close\"\n",
    "    # df.tg = 0 means not yet checked; < 0 is negative tg of delta < 0; > 0 is tg with best improvement > 1%\n",
    "    df['tg'] = ltg = 0\n",
    "    df['change'] = 0.\n",
    "    df['other'] = df.close\n",
    "    delta = 0.\n",
    "    for ltg in range(-1, -5, -1) : # tg = time gap; max time gap 4h = 60*4 T(minutes)\n",
    "        loss_check = (df.close.tshift(ltg) - df.other) / df.other * 1000 # delta in per mille: 1% == 10\n",
    "        delta = (df.close.tshift(ltg) - df.close) / df.close * 1000 # delta in per mille: 1% == 10\n",
    "        df.loc[(loss_check > 0) & (df.tg == 0), 'other'] = df.close.tshift(ltg) # note new high in other\n",
    "        df.loc[(loss_check < -2) & (df.tg == 0), ['tg', 'change']] = [ltg, delta] # equals < -0.2% loss from last high\n",
    "# reports error: ValueError: setting an array element with a sequence.\n",
    "# code snippet shows it should work\n",
    "\n",
    "        df.loc[(delta < 0) & (df.tg == 0), ['tg', 'change']] = [ltg, delta] # equals any loss from start\n",
    "# doesn't work: df.loc[(delta > 1) & (df.close.tshift(ltg) > df.close.tshift(df.tg)) & (df.tg >= 0), 'tg'] = ltg\n",
    "        df.loc[(delta > 10) & (df.tg == 0), ['tg', 'change']] = [-ltg, delta]\n",
    "\n",
    "        df.loc[(df.tg == ltg) | (df.tg == -ltg), 'change'] = delta\n",
    "# reports error: ValueError: Must have equal len keys and value when setting with an iterable\n",
    "# although it works in a previos iteration with 1T\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
